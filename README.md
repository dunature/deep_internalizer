# Deep Internalizer (æ·±åº¦å†…åŒ–é˜…è¯»å™¨)

[![Vite](https://img.shields.io/badge/Vite-7.x-646CFF?logo=vite)](https://vitejs.dev/)
[![React](https://img.shields.io/badge/React-19.x-61DAFB?logo=react)](https://react.dev/)
[![Status](https://img.shields.io/badge/Status-Internal_Beta_v0.2.0-yellow)]()
[![Performance](https://img.shields.io/badge/Performance-Optimized-brightgreen)]()
[![Dexie](https://img.shields.io/badge/IndexedDB-Local_First-blue)](https://dexie.org/)
[![PWA](https://img.shields.io/badge/PWA-Supported-orange)](https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps)

> **"The goal of reading is not to get through more books, but to let fewer things pass through your soul without leaving a trace."**
>
> **"é˜…è¯»çš„ç›®çš„ä¸æ˜¯ä¸ºäº†è¯»å®Œæ›´å¤šçš„ä¹¦ï¼Œè€Œæ˜¯ä¸ºäº†è®©æ›´å°‘çš„å†…å®¹åœ¨ç©¿è¿‡ä½ çš„çµé­‚æ—¶ä¸ç•™ç—•è¿¹ã€‚"**

**Deep Internalizer** is a specialized cognitive reading platform. It transforms passive reading into a structured, multi-layered "internalization" process, ensuring every word and concept is anchored in its original context.

**Deep Internalizer** æ˜¯ä¸€ä¸ªåŸºäºŽè®¤çŸ¥å¿ƒç†å­¦çš„æ·±åº¦é˜…è¯»å¹³å°ã€‚å®ƒå°†è¢«åŠ¨é˜…è¯»è½¬åŒ–ä¸ºç»“æž„åŒ–çš„å¤šå±‚â€œå†…åŒ–â€è¿‡ç¨‹ï¼Œç¡®ä¿æ¯ä¸ªå•è¯å’Œæ¦‚å¿µéƒ½ç‰¢å›ºåœ°é”šå®šåœ¨å…¶åŽŸå§‹è¯­å¢ƒä¸­ã€‚

---

## âœ… åŠŸèƒ½æ¨¡å—æ¦‚è¿°ï¼ˆç”¨æˆ·è§†è§’ï¼‰
- **æ–‡æ¡£å¯¼å…¥**ï¼šæ”¯æŒ `.txt/.pdf/.docx`ï¼Œè‡ªåŠ¨è§£æžä¸ºå¯é˜…è¯»çš„æ–‡æœ¬ã€‚
- **å…¨å±€è“å›¾ï¼ˆLayer 0ï¼‰**ï¼šç”Ÿæˆæ ¸å¿ƒè®ºç‚¹ä¸Žè¯­ä¹‰åˆ†å—ï¼Œå½¢æˆâ€œå…¨å±€ç†è§£åœ°å›¾â€ã€‚
- **æ²‰æµ¸å¾ªçŽ¯ï¼ˆLayer 1ï¼‰**ï¼šå¯¹æ¯ä¸ª Chunk è¿›è¡Œ 4 æ­¥æ·±åº¦å†…åŒ–ï¼š
  - å®è§‚è¯­å¢ƒ â†’ è¯æ±‡æž„å»º â†’ å‘éŸ³è®­ç»ƒ â†’ å¿ƒæµç»ƒä¹ 
- **è¯æ±‡å€ºåŠ¡ä¸Žå¤ä¹ **ï¼šåŠ å…¥å•è¯æœ¬åŽå½¢æˆâ€œå¾…å¤ä¹ å€ºåŠ¡â€ï¼Œé€šè¿‡å¤ä¹ ç•Œé¢æ¸…ç†ã€‚
- **ä¸ªäººç»Ÿè®¡**ï¼šé˜…è¯»è¿›åº¦ã€æŽŒæ¡è¯æ±‡ã€å¤ä¹ æ¬¡æ•°ã€çƒ­åŠ›å›¾æ´»è·ƒåº¦ä¸€ç›®äº†ç„¶ã€‚
- **æ•°æ®ç®¡ç†**ï¼šå¤‡ä»½ã€å¯¼å…¥ã€æ¸…ç†ç¼“å­˜/è¯æ±‡/è¿›åº¦ï¼Œç¡®ä¿æœ¬åœ°æ•°æ®å¯æŽ§ã€‚
- **æœ¬åœ° TTS**ï¼šé«˜è´¨é‡è¯­éŸ³æœ—è¯»ï¼Œæ”¯æŒç¼“å­˜ä¸Žå¤ç”¨ï¼Œç¦»çº¿ä¹Ÿèƒ½æµç•…ä½¿ç”¨ã€‚

---

## ðŸ§­ ä½¿ç”¨æµç¨‹ï¼ˆç”¨æˆ·è§†è§’ï¼‰
1. **å¯¼å…¥æ–‡æœ¬/æ–‡æ¡£** â†’ ç³»ç»Ÿè‡ªåŠ¨åˆ†æžå¹¶ç”Ÿæˆå…¨å±€é€»è¾‘åœ°å›¾ï¼ˆLayer 0ï¼‰
2. **é€‰æ‹© Chunk** â†’ è¿›å…¥ 4 æ­¥æ²‰æµ¸å¾ªçŽ¯ï¼ˆLayer 1ï¼‰
3. **è¯æ±‡æž„å»º** â†’ åŠ å…¥å•è¯æœ¬å½¢æˆå¤ä¹ å€ºåŠ¡
4. **é˜…è¯»æŽ¨è¿›** â†’ å®Œæˆ Chunk åŽè®°å½•è¿›åº¦ä¸Žç»Ÿè®¡
5. **å¤ä¹ æ¸…å€º** â†’ åœ¨â€œå¤ä¹ é¡µé¢â€å®Œæˆ Keep / Archive
6. **ä¸ªäººç»Ÿè®¡ & æ•°æ®ç®¡ç†** â†’ æŸ¥çœ‹å­¦ä¹ è½¨è¿¹ã€å¯¼å‡ºæ•°æ®

---

## ðŸ†• æ–°æ‰‹ä½¿ç”¨è¯´æ˜Žï¼ˆä»Žé›¶å¼€å§‹ï¼‰

### 0) å¿…å¤‡çŽ¯å¢ƒ
- **Node.js 18+**
- **Python 3.11+**ï¼ˆç”¨äºŽæœ¬åœ° TTSï¼‰
- **Ollama**ï¼ˆæœ¬åœ°å¤§æ¨¡åž‹æŽ¨ç†ï¼‰

---

### 1) å®‰è£…å¹¶å¯åŠ¨æœ¬åœ° LLMï¼ˆOllamaï¼‰
1. å®‰è£… Ollama  
2. æ‹‰å–æ¨¡åž‹ï¼ˆé»˜è®¤ä½¿ç”¨ `llama3.1:latest`ï¼‰ï¼š
   ```bash
   ollama pull llama3.1:latest
   ```
3. å¯åŠ¨ Ollamaï¼ˆé»˜è®¤ç«¯å£ 11434ï¼‰

å¦‚æžœä½ æƒ³ä½¿ç”¨äº‘ç«¯æ¨¡åž‹ï¼ˆDeepSeek/GLMï¼‰ï¼Œè¯·åœ¨çŽ¯å¢ƒå˜é‡ä¸­é…ç½®ï¼š
```bash
VITE_LLM_PROVIDER=deepseek
VITE_DEEPSEEK_BASE_URL=https://api.deepseek.com
VITE_DEEPSEEK_MODEL=deepseek-chat
VITE_DEEPSEEK_API_KEY=your_key_here
```

---

### 2) å®‰è£…å¹¶å¯åŠ¨æœ¬åœ° TTSï¼ˆæŽ¨èï¼‰
æœ¬é¡¹ç›®å†…ç½® Kokoro-TTSï¼Œæœ¬åœ°è¿è¡Œå³å¯ã€‚

#### ä¸€é”®å¯åŠ¨ï¼ˆmacOS/Linuxï¼‰
```bash
./scripts/start_tts.sh
```

å¦‚æžœ `torch` å®‰è£…å¤±è´¥ï¼Œè¯·æ ¹æ®ä½ çš„ç³»ç»Ÿå‚è€ƒ PyTorch å®˜æ–¹å®‰è£…æŒ‡å¼•åŽé‡è¯•ã€‚

#### Windows ç”¨æˆ·å»ºè®®
- ä½¿ç”¨ WSL è¿è¡Œ `start_tts.sh`
- æˆ–æ‰‹åŠ¨æ‰§è¡Œä»¥ä¸‹æ­¥éª¤ï¼š
  ```bash
  cd scripts/tts_server
  python -m venv venv
  venv\Scripts\activate
  pip install -r requirements.txt
  python server.py
  ```

TTS é»˜è®¤åœ°å€ï¼š
```
http://localhost:8000/v1/audio/speech
```
å¦‚æžœä½ åœ¨å…¶ä»–ç«¯å£è¿è¡Œï¼Œå¯ä»¥åœ¨ `.env` ä¸­è®¾ç½®ï¼š
```bash
VITE_TTS_API_URL=http://localhost:8000/v1/audio/speech
```

---

### 3) å¯åŠ¨å‰ç«¯é¡¹ç›®
```bash
npm install
npm run dev
```
æ‰“å¼€æµè§ˆå™¨è®¿é—®ï¼š
```
http://localhost:5173
```

---

## ðŸš€ Performance Optimizations (2026 Update)
**æœ€æ–°æ€§èƒ½ä¼˜åŒ–**

We have re-engineered the core data flow to achieve a **"Zero-Wait"** user experience.
æˆ‘ä»¬é‡æž„äº†æ ¸å¿ƒæ•°æ®æµï¼Œå®žçŽ°äº†**â€œé›¶ç­‰å¾…â€**çš„ç”¨æˆ·ä½“éªŒã€‚

### 1. Parallel Intelligence (å¹¶è¡Œæ™ºèƒ½)
- **Problem**: Sequential execution of "Thesis Synthesis" and "Document Chunking" caused long wait times during import.
- **Solution**: Implemented `Promise.all` parallelism to run both LLM tasks concurrently, reducing import time by **~50%**.
- **é—®é¢˜**ï¼šâ€œæ ¸å¿ƒè®ºç‚¹åˆæˆâ€ä¸Žâ€œæ–‡æ¡£åˆ‡ç‰‡â€çš„ä¸²è¡Œæ‰§è¡Œå¯¼è‡´å¯¼å…¥æ—¶é—´è¿‡é•¿ã€‚
- **æ–¹æ¡ˆ**ï¼šé‡‡ç”¨ `Promise.all` å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ª LLM ä»»åŠ¡ï¼Œå¯¼å…¥é€Ÿåº¦æå‡ **~50%**ã€‚

### 2. Zero-Wait Interaction (é›¶ç­‰å¾…äº¤äº’)
- **Problem**: Transitioning to Layer 1 required waiting for keyword extraction (LLM), blocking the UI.
- **Solution**: **Immediate Transition + Background Prefetch**. The UI enters the reading mode instantly while the `PrefetchService` loads keywords and TTS audio in the background.
- **é—®é¢˜**ï¼šè¿›å…¥ Layer 1 é˜…è¯»æ¨¡å¼éœ€è¦ç­‰å¾…å…³é”®è¯æå–ï¼Œé˜»å¡žäº†ç•Œé¢ã€‚
- **æ–¹æ¡ˆ**ï¼š**ç«‹å³è·³è½¬ + åŽå°é¢„åŠ è½½**ã€‚ç•Œé¢çž¬é—´åˆ‡æ¢ï¼Œ`PrefetchService` åœ¨åŽå°é™é»˜åŠ è½½å…³é”®è¯å’Œ TTS éŸ³é¢‘ã€‚

### 3. Smart Audio Caching (æ™ºèƒ½éŸ³é¢‘ç¼“å­˜)
- **Strategy**:
  - **Words**: Cached permanently in IndexedDB (`wordAudio`). Reused across all documents.
  - **Syllables**: Common suffixes/prefixes (e.g., `-tion`, `pre-`) are cached globally.
  - **Sentences**: Generated on-demand (no cache).
- **Result**: Drastically reduced TTS API calls and network latency.
- **ç­–ç•¥**ï¼š
  - **å•è¯**ï¼šæ°¸ä¹…ç¼“å­˜äºŽ IndexedDB (`wordAudio`)ï¼Œè·¨æ–‡ç« å¤ç”¨ã€‚
  - **éŸ³èŠ‚**ï¼šå…¨å±€ç¼“å­˜å¸¸ç”¨è¯ç¼€ï¼ˆå¦‚ `-tion`, `pre-`ï¼‰ã€‚
  - **å¥å­**ï¼šå³æ—¶ç”Ÿæˆï¼Œä¸å ç”¨ç¼“å­˜ã€‚
- **ç»“æžœ**ï¼šå¤§å¹…å‡å°‘ TTS API è°ƒç”¨å’Œç½‘ç»œå»¶è¿Ÿã€‚

---

## ðŸ—ï¸ Architecture: The Dual-Layer Funnel
**åŒå±‚æ¼æ–—æž¶æž„**

### Layer 0: Global Strategic Map (å…¨å±€æˆ˜ç•¥åœ°å›¾)
- **Core Thesis**: Synthesizes the entire document into a single, high-impact thesis statement using Local LLM.
- **Semantic Segmentation**: Breaks documents into thematic chunks (3-8 sentences) based on meaning, not length.
- **æ ¸å¿ƒè®ºç‚¹**ï¼šåˆ©ç”¨æœ¬åœ° LLM å°†å…¨æ–‡æµ“ç¼©ä¸ºå”¯ä¸€çš„å¼ºåŠ›è®ºç‚¹ã€‚
- **è¯­ä¹‰åˆ‡ç‰‡**ï¼šåŸºäºŽè¯­ä¹‰è€Œéžé•¿åº¦ï¼Œå°†æ–‡æ¡£æ‹†åˆ†ä¸ºä¸»é¢˜åˆ‡ç‰‡ï¼ˆæ¯ç‰‡ 3-8 å¥ï¼‰ã€‚

### Layer 1: Tactical Immersion Cycle (æˆ˜æœ¯æ²‰æµ¸å¾ªçŽ¯)
A 4-step loop for every semantic chunk:
æ¯ä¸ªè¯­ä¹‰åˆ‡ç‰‡çš„ 4 æ­¥å¾ªçŽ¯ï¼š

1.  **Macro Context (å®è§‚è¯­å¢ƒ)**: Review the chunk's summary within the global framework.
2.  **Vocabulary Build (è¯æ±‡æž„å»º)**: Extract 5-8 key terms with **X-Ray Context** (Long-press to see origin).
3.  **Articulation (å‘éŸ³è®­ç»ƒ)**: Train the "inner ear" with IPA transcriptions and high-fidelity TTS.
4.  **Flow Practice (å¿ƒæµç»ƒä¹ )**: Continuous reading with real-time WPM tracking.

1.  **å®è§‚è¯­å¢ƒ**ï¼šåœ¨å…¨å±€æ¡†æž¶ä¸‹å®¡è§†åˆ‡ç‰‡æ‘˜è¦ã€‚
2.  **è¯æ±‡æž„å»º**ï¼šæå– 5-8 ä¸ªæ ¸å¿ƒè¯ï¼Œæ”¯æŒ**Xå…‰è¯­å¢ƒ**ï¼ˆé•¿æŒ‰æŸ¥çœ‹åŽŸæ–‡å‡ºå¤„ï¼‰ã€‚
3.  **å‘éŸ³è®­ç»ƒ**ï¼šé€šè¿‡ IPA éŸ³æ ‡å’Œé«˜ä¿çœŸ TTS è®­ç»ƒâ€œå†…è€³â€ã€‚
4.  **å¿ƒæµç»ƒä¹ **ï¼šå®žæ—¶ WPM è¿½è¸ªçš„è¿žç»­é˜…è¯»è®­ç»ƒã€‚

---

## ðŸ› ï¸ Technology Stack (æŠ€æœ¯æ ˆ)

### Frontend (User Interface)
- **Framework**: React 19 + Vite 7
- **State Management**: Zustand (UI State) + Context API
- **Persistence**: Dexie.js (IndexedDB Wrapper) - **Local-First & Offline-Ready**
- **Styling**: Vanilla CSS Variables (Magazine Aesthetic)

### Backend Services (Local AI)
- **Cognitive Model**: Ollama (Llama 3.1) - for logical analysis & extraction.
- **Voice Engine**: Kokoro-TTS (Python/ONNX) - 82M parameter model for natural speech.
  - *New*: **Request Deduplication** & **LRU Cache** implemented in `ttsService.js`.

---

## ðŸ“‚ Project Structure (é¡¹ç›®ç»“æž„)

```text
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Layer0/          # Global Map (å…¨å±€åœ°å›¾)
â”‚   â”œâ”€â”€ Layer1/          # Immersion Loop (æ²‰æµ¸å¾ªçŽ¯)
â”‚   â””â”€â”€ common/          # Shared Generators (Thinking UI, etc.)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chunkingService.js  # LLM Bridge (Ollama)
â”‚   â”œâ”€â”€ ttsService.js       # Audio Engine (Caching enabled)
â”‚   â””â”€â”€ prefetchService.js  # Background Loading Manager
â”œâ”€â”€ db/
â”‚   â””â”€â”€ schema.js        # IndexedDB Schema (v3)
â””â”€â”€ hooks/
    â””â”€â”€ useTTS.js        # React Adapter for Speech
```

---

## ðŸ“– User Guide: The Cognitive Journey (ç”¨æˆ·æŒ‡å—)

Detailed instructions with visual aids can be found in the [Root READ.md](../READ.md). Below is a summary of the 4-step immersion loop:

### 1. Ingestion & Analysis
Paste text or upload documents. The "Thinking UI" reveals the AI's logic mapping process.
![Import](../docs/images/img_import.png)

### 2. Global Logic Map (Layer 0)
The document is synthesized into a core thesis and thematic chunks.
![Logic Map](../docs/images/img_layer0.png)

### 3. The Immersion Loop (Layer 1)
- **Macro Context**: Establish a semantic framework.
- **Vocabulary Build**: Interactive flashcards with X-Ray context.
- **Articulation**: Train phonological memory with TTS & IPA.
- **Flow Practice**: Achieve reading fluency (WPM tracking).

![Immersion Loop](../docs/images/img_step2.png)

---

## Quick Start (å¿«é€Ÿå¼€å§‹)

### Prerequisites (å‰ç½®è¦æ±‚)
- Node.js 18+
- Python 3.11+ (for TTS)
- Ollama (running locally)

### 1. Start Frontend (å¯åŠ¨å‰ç«¯)
```bash
npm install
npm run dev
# App runs on http://localhost:5173
```

### 1.1 LLM Providers (Optional)
By default the app uses local Ollama. You can switch to remote providers for speed.

```bash
# Provider: ollama | deepseek | glm
VITE_LLM_PROVIDER=ollama

# Ollama
VITE_OLLAMA_BASE_URL=http://localhost:11434
VITE_OLLAMA_MODEL=llama3.1:latest

# DeepSeek
VITE_DEEPSEEK_BASE_URL=https://api.deepseek.com
VITE_DEEPSEEK_MODEL=deepseek-chat
VITE_DEEPSEEK_API_KEY=your_key_here

# GLM (Z.AI)
VITE_GLM_BASE_URL=https://api.z.ai/api/paas/v4
VITE_GLM_MODEL=glm-4.7
VITE_GLM_API_KEY=your_key_here
```

> NOTE: Remote APIs may require a backend proxy if CORS is enforced by the provider.

### 2. Start TTS Server (å¯åŠ¨è¯­éŸ³æœåŠ¡)
```bash
./scripts/start_tts.sh
# API runs on http://localhost:8000
```

---

## ðŸ“œ License
MIT - Designed for personal growth and deep literacy.
MIT - ä¸ºä¸ªäººæˆé•¿ä¸Žæ·±åº¦é˜…è¯»è€Œè®¾è®¡ã€‚

---

> [!NOTE]
> **Internal Beta v0.2.0**: This version focuses on "Zero-Wait" performance optimizations and architectural refactoring for a smoother reading experience.
