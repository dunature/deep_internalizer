# Deep Internalizer (æ·±åº¦å†…åŒ–é˜…è¯»å™¨)

[![Vite](https://img.shields.io/badge/Vite-7.x-646CFF?logo=vite)](https://vitejs.dev/)
[![React](https://img.shields.io/badge/React-19.x-61DAFB?logo=react)](https://react.dev/)
[![Performance](https://img.shields.io/badge/Performance-Optimized-brightgreen)]()
[![Dexie](https://img.shields.io/badge/IndexedDB-Local_First-blue)](https://dexie.org/)
[![PWA](https://img.shields.io/badge/PWA-Supported-orange)](https://developer.mozilla.org/en-US/docs/Web/Progressive_web_apps)

> **"The goal of reading is not to get through more books, but to let fewer things pass through your soul without leaving a trace."**
>
> **"é˜…è¯»çš„ç›®çš„ä¸æ˜¯ä¸ºäº†è¯»å®Œæ›´å¤šçš„ä¹¦ï¼Œè€Œæ˜¯ä¸ºäº†è®©æ›´å°‘çš„å†…å®¹åœ¨ç©¿è¿‡ä½ çš„çµé­‚æ—¶ä¸ç•™ç—•è¿¹ã€‚"**

**Deep Internalizer** is a specialized cognitive reading platform. It transforms passive reading into a structured, multi-layered "internalization" process, ensuring every word and concept is anchored in its original context.

**Deep Internalizer** æ˜¯ä¸€ä¸ªåŸºäºè®¤çŸ¥å¿ƒç†å­¦çš„æ·±åº¦é˜…è¯»å¹³å°ã€‚å®ƒå°†è¢«åŠ¨é˜…è¯»è½¬åŒ–ä¸ºç»“æ„åŒ–çš„å¤šå±‚â€œå†…åŒ–â€è¿‡ç¨‹ï¼Œç¡®ä¿æ¯ä¸ªå•è¯å’Œæ¦‚å¿µéƒ½ç‰¢å›ºåœ°é”šå®šåœ¨å…¶åŸå§‹è¯­å¢ƒä¸­ã€‚

---

## ğŸš€ Performance Optimizations (2026 Update)
**æœ€æ–°æ€§èƒ½ä¼˜åŒ–**

We have re-engineered the core data flow to achieve a **"Zero-Wait"** user experience.
æˆ‘ä»¬é‡æ„äº†æ ¸å¿ƒæ•°æ®æµï¼Œå®ç°äº†**â€œé›¶ç­‰å¾…â€**çš„ç”¨æˆ·ä½“éªŒã€‚

### 1. Parallel Intelligence (å¹¶è¡Œæ™ºèƒ½)
- **Problem**: Sequential execution of "Thesis Synthesis" and "Document Chunking" caused long wait times during import.
- **Solution**: Implemented `Promise.all` parallelism to run both LLM tasks concurrently, reducing import time by **~50%**.
- **é—®é¢˜**ï¼šâ€œæ ¸å¿ƒè®ºç‚¹åˆæˆâ€ä¸â€œæ–‡æ¡£åˆ‡ç‰‡â€çš„ä¸²è¡Œæ‰§è¡Œå¯¼è‡´å¯¼å…¥æ—¶é—´è¿‡é•¿ã€‚
- **æ–¹æ¡ˆ**ï¼šé‡‡ç”¨ `Promise.all` å¹¶è¡Œæ‰§è¡Œä¸¤ä¸ª LLM ä»»åŠ¡ï¼Œå¯¼å…¥é€Ÿåº¦æå‡ **~50%**ã€‚

### 2. Zero-Wait Interaction (é›¶ç­‰å¾…äº¤äº’)
- **Problem**: Transitioning to Layer 1 required waiting for keyword extraction (LLM), blocking the UI.
- **Solution**: **Immediate Transition + Background Prefetch**. The UI enters the reading mode instantly while the `PrefetchService` loads keywords and TTS audio in the background.
- **é—®é¢˜**ï¼šè¿›å…¥ Layer 1 é˜…è¯»æ¨¡å¼éœ€è¦ç­‰å¾…å…³é”®è¯æå–ï¼Œé˜»å¡äº†ç•Œé¢ã€‚
- **æ–¹æ¡ˆ**ï¼š**ç«‹å³è·³è½¬ + åå°é¢„åŠ è½½**ã€‚ç•Œé¢ç¬é—´åˆ‡æ¢ï¼Œ`PrefetchService` åœ¨åå°é™é»˜åŠ è½½å…³é”®è¯å’Œ TTS éŸ³é¢‘ã€‚

### 3. Smart Audio Caching (æ™ºèƒ½éŸ³é¢‘ç¼“å­˜)
- **Strategy**:
  - **Words**: Cached permanently in IndexedDB (`wordAudio`). Reused across all documents.
  - **Syllables**: Common suffixes/prefixes (e.g., `-tion`, `pre-`) are cached globally.
  - **Sentences**: Generated on-demand (no cache).
- **Result**: Drastically reduced TTS API calls and network latency.
- **ç­–ç•¥**ï¼š
  - **å•è¯**ï¼šæ°¸ä¹…ç¼“å­˜äº IndexedDB (`wordAudio`)ï¼Œè·¨æ–‡ç« å¤ç”¨ã€‚
  - **éŸ³èŠ‚**ï¼šå…¨å±€ç¼“å­˜å¸¸ç”¨è¯ç¼€ï¼ˆå¦‚ `-tion`, `pre-`ï¼‰ã€‚
  - **å¥å­**ï¼šå³æ—¶ç”Ÿæˆï¼Œä¸å ç”¨ç¼“å­˜ã€‚
- **ç»“æœ**ï¼šå¤§å¹…å‡å°‘ TTS API è°ƒç”¨å’Œç½‘ç»œå»¶è¿Ÿã€‚

---

## ğŸ—ï¸ Architecture: The Dual-Layer Funnel
**åŒå±‚æ¼æ–—æ¶æ„**

### Layer 0: Global Strategic Map (å…¨å±€æˆ˜ç•¥åœ°å›¾)
- **Core Thesis**: Synthesizes the entire document into a single, high-impact thesis statement using Local LLM.
- **Semantic Segmentation**: Breaks documents into thematic chunks (3-8 sentences) based on meaning, not length.
- **æ ¸å¿ƒè®ºç‚¹**ï¼šåˆ©ç”¨æœ¬åœ° LLM å°†å…¨æ–‡æµ“ç¼©ä¸ºå”¯ä¸€çš„å¼ºåŠ›è®ºç‚¹ã€‚
- **è¯­ä¹‰åˆ‡ç‰‡**ï¼šåŸºäºè¯­ä¹‰è€Œéé•¿åº¦ï¼Œå°†æ–‡æ¡£æ‹†åˆ†ä¸ºä¸»é¢˜åˆ‡ç‰‡ï¼ˆæ¯ç‰‡ 3-8 å¥ï¼‰ã€‚

### Layer 1: Tactical Immersion Cycle (æˆ˜æœ¯æ²‰æµ¸å¾ªç¯)
A 4-step loop for every semantic chunk:
æ¯ä¸ªè¯­ä¹‰åˆ‡ç‰‡çš„ 4 æ­¥å¾ªç¯ï¼š

1.  **Macro Context (å®è§‚è¯­å¢ƒ)**: Review the chunk's summary within the global framework.
2.  **Vocabulary Build (è¯æ±‡æ„å»º)**: Extract 5-8 key terms with **X-Ray Context** (Long-press to see origin).
3.  **Articulation (å‘éŸ³è®­ç»ƒ)**: Train the "inner ear" with IPA transcriptions and high-fidelity TTS.
4.  **Flow Practice (å¿ƒæµç»ƒä¹ )**: Continuous reading with real-time WPM tracking.

1.  **å®è§‚è¯­å¢ƒ**ï¼šåœ¨å…¨å±€æ¡†æ¶ä¸‹å®¡è§†åˆ‡ç‰‡æ‘˜è¦ã€‚
2.  **è¯æ±‡æ„å»º**ï¼šæå– 5-8 ä¸ªæ ¸å¿ƒè¯ï¼Œæ”¯æŒ**Xå…‰è¯­å¢ƒ**ï¼ˆé•¿æŒ‰æŸ¥çœ‹åŸæ–‡å‡ºå¤„ï¼‰ã€‚
3.  **å‘éŸ³è®­ç»ƒ**ï¼šé€šè¿‡ IPA éŸ³æ ‡å’Œé«˜ä¿çœŸ TTS è®­ç»ƒâ€œå†…è€³â€ã€‚
4.  **å¿ƒæµç»ƒä¹ **ï¼šå®æ—¶ WPM è¿½è¸ªçš„è¿ç»­é˜…è¯»è®­ç»ƒã€‚

---

## ğŸ› ï¸ Technology Stack (æŠ€æœ¯æ ˆ)

### Frontend (User Interface)
- **Framework**: React 19 + Vite 7
- **State Management**: Zustand (UI State) + Context API
- **Persistence**: Dexie.js (IndexedDB Wrapper) - **Local-First & Offline-Ready**
- **Styling**: Vanilla CSS Variables (Magazine Aesthetic)

### Backend Services (Local AI)
- **Cognitive Model**: Ollama (Llama 3.1) - for logical analysis & extraction.
- **Voice Engine**: Kokoro-TTS (Python/ONNX) - 82M parameter model for natural speech.
  - *New*: **Request Deduplication** & **LRU Cache** implemented in `ttsService.js`.

---

## ğŸ“‚ Project Structure (é¡¹ç›®ç»“æ„)

```text
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ Layer0/          # Global Map (å…¨å±€åœ°å›¾)
â”‚   â”œâ”€â”€ Layer1/          # Immersion Loop (æ²‰æµ¸å¾ªç¯)
â”‚   â””â”€â”€ common/          # Shared Generators (Thinking UI, etc.)
â”œâ”€â”€ services/
â”‚   â”œâ”€â”€ chunkingService.js  # LLM Bridge (Ollama)
â”‚   â”œâ”€â”€ ttsService.js       # Audio Engine (Caching enabled)
â”‚   â””â”€â”€ prefetchService.js  # Background Loading Manager
â”œâ”€â”€ db/
â”‚   â””â”€â”€ schema.js        # IndexedDB Schema (v3)
â””â”€â”€ hooks/
    â””â”€â”€ useTTS.js        # React Adapter for Speech
```

## ï¿½ Quick Start (å¿«é€Ÿå¼€å§‹)

### Prerequisites (å‰ç½®è¦æ±‚)
- Node.js 18+
- Python 3.11+ (for TTS)
- Ollama (running locally)

### 1. Start Frontend (å¯åŠ¨å‰ç«¯)
```bash
npm install
npm run dev
# App runs on http://localhost:5173
```

### 2. Start TTS Server (å¯åŠ¨è¯­éŸ³æœåŠ¡)
```bash
./scripts/start_tts.sh
# API runs on http://localhost:8000
```

---

## ğŸ“œ License
MIT - Designed for personal growth and deep literacy.
MIT - ä¸ºä¸ªäººæˆé•¿ä¸æ·±åº¦é˜…è¯»è€Œè®¾è®¡ã€‚
